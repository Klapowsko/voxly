# Voxly - TranscriÃ§Ã£o de Ãudio com Whisper

AplicaÃ§Ã£o completa para gravar Ã¡udio, transcrever usando Whisper (open source) e gerar tÃ³picos organizados em Markdown, ideal para uso com Obsidian.

**100% Open Source e Gratuito** - Usa modelos locais sem necessidade de APIs pagas.

## ğŸ—ï¸ Arquitetura

- **Frontend**: Next.js 14 com TypeScript e Tailwind CSS
- **Backend**: FastAPI (Python) com arquitetura modular
  - `app/audio`: Gerenciamento de upload e armazenamento de Ã¡udios
  - `app/transcription`: ServiÃ§o de transcriÃ§Ã£o usando Whisper local (openai-whisper)
  - `app/topics`: GeraÃ§Ã£o de tÃ³picos em Markdown usando Ollama/Hugging Face/mÃ©todo simples
  - `app/api`: Rotas da API REST

A arquitetura modular permite fÃ¡cil extraÃ§Ã£o em microserviÃ§os no futuro.

## ğŸ“‹ PrÃ©-requisitos

- Docker e Docker Compose instalados
- Navegador moderno com suporte a MediaRecorder API
- (Opcional) Ollama instalado e rodando para melhor qualidade na geraÃ§Ã£o de tÃ³picos
- (Recomendado para Ã¡udios longos) GPU NVIDIA com CUDA para processamento mais rÃ¡pido

## ğŸš€ InÃ­cio RÃ¡pido

1. **Clone o repositÃ³rio e configure as variÃ¡veis de ambiente:**

Os arquivos `.env` serÃ£o criados automaticamente pelo Makefile. Se preferir criar manualmente:

```bash
cp backend/env.example backend/.env
cp frontend/env.example frontend/.env
```

Edite os arquivos `.env` se necessÃ¡rio. Por padrÃ£o, usa modelos open source:
- Whisper local (openai-whisper) para transcriÃ§Ã£o
- Ollama (opcional) ou Hugging Face para geraÃ§Ã£o de tÃ³picos

**Opcional - Para melhor qualidade nos tÃ³picos, instale Ollama:**
```bash
# Instale Ollama: https://ollama.ai
# Baixe um modelo:
ollama pull llama3.2
```

2. **Inicie os serviÃ§os:**

```bash
docker-compose up --build
```

Ou usando o Makefile:

```bash
make build
make up
```

3. **Acesse a aplicaÃ§Ã£o:**

- Frontend: http://localhost:3000
- Backend API: http://localhost:8000
- Health check: http://localhost:8000/health

## ğŸ“– Como Usar

### GravaÃ§Ã£o de Ãudio

1. Clique em **"Gravar"** para iniciar a gravaÃ§Ã£o
2. O timer mostra a duraÃ§Ã£o da gravaÃ§Ã£o
3. Clique em **"Concluir"** quando terminar
4. O sistema processarÃ¡ automaticamente:
   - Upload do Ã¡udio
   - TranscriÃ§Ã£o com Whisper
   - GeraÃ§Ã£o de tÃ³picos em Markdown

### Upload Manual

Alternativamente, vocÃª pode fazer upload de um arquivo de Ã¡udio clicando em **"Fazer Upload de Arquivo"**.

### Resultado

ApÃ³s o processamento, vocÃª verÃ¡:
- A transcriÃ§Ã£o completa do Ã¡udio
- Os tÃ³picos organizados em Markdown
- Um botÃ£o para baixar o arquivo `.md` (compatÃ­vel com Obsidian)

### Ãudios Longos

O sistema suporta Ã¡udios de qualquer duraÃ§Ã£o, incluindo:
- **Palestras de 20-30 minutos**
- **SermÃµes de 1 hora ou mais**
- **VÃ­deos longos** (o Whisper extrai o Ã¡udio automaticamente)

**Notas importantes:**
- Ãudios longos podem levar mais tempo para processar (especialmente em CPU)
- Com GPU, o processamento Ã© significativamente mais rÃ¡pido
- O Whisper processa automaticamente Ã¡udios longos em segmentos, **sem limite rÃ­gido de duraÃ§Ã£o**
- Recomenda-se usar modelo `base` ou `small` para Ã¡udios muito longos (mais rÃ¡pido)
- Modelos `medium` ou `large` oferecem melhor qualidade, mas sÃ£o mais lentos
- O sistema remove automaticamente repetiÃ§Ãµes excessivas da transcriÃ§Ã£o

## ğŸ”§ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

#### Backend (`backend/.env`)

- `APP_API_TOKEN`: Token de autenticaÃ§Ã£o para a API (padrÃ£o: `dev-token`)
- `APP_WHISPER_MODEL`: Modelo Whisper local a usar - `tiny`, `base`, `small`, `medium`, `large` (padrÃ£o: `base`)
- `APP_WHISPER_DEVICE`: Device para Whisper - `auto`, `cuda`, `cpu` (padrÃ£o: `auto`)
- `APP_OLLAMA_MODEL`: Modelo Ollama para tÃ³picos, ou `None` para desabilitar (padrÃ£o: `llama3.2`)
- `APP_OLLAMA_URL`: URL do servidor Ollama (padrÃ£o: `http://localhost:11434`)
- `APP_DATA_DIR`: DiretÃ³rio para armazenar arquivos (padrÃ£o: `/data`)

**Nota**: Se Ollama nÃ£o estiver disponÃ­vel, o sistema usa Hugging Face como fallback, e por Ãºltimo um mÃ©todo simples sem IA.

#### Frontend (`frontend/.env`)

- `NEXT_PUBLIC_API_URL`: URL da API backend (padrÃ£o: `http://localhost:8000`)
- `NEXT_PUBLIC_API_TOKEN`: Token de autenticaÃ§Ã£o (deve corresponder ao backend)

### Volumes Docker

Os arquivos sÃ£o armazenados no volume `./data`:
- `data/uploads/`: Ãudios enviados
- `data/outputs/`: Arquivos Markdown gerados

## ğŸ§ª Testes

Execute os testes do backend:

```bash
docker-compose run --rm backend pytest
```

Ou usando o Makefile:

```bash
make test
```

## ğŸ“ Estrutura do Projeto

```
voxly/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/          # Rotas da API
â”‚   â”‚   â”œâ”€â”€ audio/        # MÃ³dulo de Ã¡udio
â”‚   â”‚   â”œâ”€â”€ transcription/# MÃ³dulo de transcriÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ topics/       # MÃ³dulo de geraÃ§Ã£o de tÃ³picos
â”‚   â”‚   â”œâ”€â”€ config.py     # ConfiguraÃ§Ãµes
â”‚   â”‚   â”œâ”€â”€ deps.py       # DependÃªncias FastAPI
â”‚   â”‚   â””â”€â”€ main.py       # AplicaÃ§Ã£o principal
â”‚   â”œâ”€â”€ tests/            # Testes
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ page.tsx      # PÃ¡gina principal
â”‚   â”‚   â”œâ”€â”€ layout.tsx
â”‚   â”‚   â””â”€â”€ globals.css
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ data/                 # Volume de dados (criado automaticamente)
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

## ğŸ” AutenticaÃ§Ã£o

A API usa autenticaÃ§Ã£o simples via header `X-API-TOKEN`. Configure o mesmo token no frontend e backend.

## ğŸ¯ Casos de Uso

- Gravar palestras e gerar notas estruturadas
- Transcrever sermÃµes e criar resumos temÃ¡ticos
- Processar reuniÃµes e extrair pontos principais
- Qualquer situaÃ§Ã£o onde vocÃª precisa transformar Ã¡udio em conteÃºdo organizado

## ğŸš§ Desenvolvimento

### Modo de Desenvolvimento

Os volumes estÃ£o configurados para hot-reload:
- Backend: alteraÃ§Ãµes em `backend/app/` sÃ£o refletidas automaticamente
- Frontend: alteraÃ§Ãµes em `frontend/app/` sÃ£o refletidas automaticamente

### Adicionar Novos MÃ³dulos

A arquitetura modular facilita a adiÃ§Ã£o de novos mÃ³dulos:

1. Crie uma nova pasta em `backend/app/`
2. Implemente o serviÃ§o com funÃ§Ãµes assÃ­ncronas
3. Importe e use no mÃ³dulo `api/routes.py`

## ğŸ“ LicenÃ§a

Este projeto Ã© de cÃ³digo aberto.

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para abrir issues e pull requests.

